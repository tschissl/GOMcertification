{
    "contents" : "---\ntitle: \"MUH-1 Certification\"\nauthor: \"TCM\"\ndate: \"Sunday, July 20, 2014\"\noutput:\n  pdf_document: default\n  html_document:\n    mathjax: default\n    self_contained: yes\n  word_document:\n    fig_caption: yes\n---\nAutomated analysing submitted data for MUH-1 based on defined outliers\n========================================================\nThomas Meisel (`r as.character(Sys.Date())`)  \n\n### defining the RM and measurand to be analysed\n```{r defining the measurand and RM}\nrefmat <- 'MUH' # defining the RM\n\n``` \nopts_chunk$set(dev=\"png\",dev.args=list(type=\"cairo\"), dpi=300)\noptions(base64_images = 'inline')\n### general comments to the design \n\nThe data for this interlaboratory comparison based certification of property values were analysed by 36 labs following the nested design approached as proposed the IAG certification protocol. Participating labs received 3 packages of OKUM and MUH-1 respectively and one package of GAS. The latter was supplied as a \"traceablility\" sample and is here used for quality control purposes. It was the task of the labs to prepare two independent sample preparations (i.e. digstions) of each packet and analyse the preparations on two different days. Labs thus should have submitted 12 values (3x2x2 PacketxPrepxDay). \nThe outliers have been selected based in Youden plots, Mandel's k and detection limit criteria. In this file the property values and the uncertainties are calculated for all analytes of a specific candidate `r refmat`\n\n\n\n```{r}\n'%p%' <- function(x, y) {as.character(paste (x, y, sep =\"\"))}\ndf <- data.frame(cbind(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0))\nnames(df) <- c(\"date\", \"RM\", \"measurand\", \"mean.before\", \"mean.after\", \"median.before\", \"median.after\", \"median.after.noPP\", \"unit\", \"sL\", \"sbb\", \"sr\", \"u\", \"u.alternative\", \"t.value\", \"outlier\", \"labs remaining\", \"based on\", \"property value\", \"U\") # needed only the first time\ndf <- df[!1,]\nwrite.table(df, \"df1.txt\", row.names=FALSE) # needed only the first time\n\n```\n\n```{r loading packages, results='hide', include=FALSE}\nlibrary(ggplot2) # needed for most plots in this document\n# library(devtools) #needed for \"order_by\"\n# install_github(\"plotflow\", \"trinker\")\nlibrary(plotflow) #needed for \"order_by\" # install_github(\"plotflow\", \"trinker\")\nlibrary(metRology) #for mandel k and h calculations\nlibrary(ape) # needed for varcomp (variance component) extraction\nlibrary(nlme) # needed for lme\nrequire(plyr) # needed for ddply\nlibrary(knitr)\nlibrary(gridExtra)\nopts_chunk$set(dev=\"png\",dev.args=list(type=\"cairo\"), dpi=300)\noptions(base64_images = 'inline')\n\n#### defining the plotting theme\n```{r mytheme, include=FALSE}\nmytheme <- theme_grey() + theme(plot.title = element_text(colour = \"black\", size = rel(2))) + theme(axis.title.x = element_text(size = rel(1.8)))+ theme(axis.title.y = element_text(size = rel(1.8))) +theme(axis.text.x = element_text(size = rel(1.5))) + theme(axis.text.y = element_text(size = rel(1.5))) + theme(legend.title = element_text(size = rel(1))) +theme(legend.text = element_text(size = rel(0.8)))\n```\n\n\n```{r, tidy=TRUE}\n# Data for certification project was gathered and joined in Excel. The files were exported from Excel as xxxx.csv files to make them universially readable. For this markdown the data is stored in the \"root/documents\" directory.\n# Data is loaded (\"GOMGather1.R\") and merged (\"GOMMerge.R\") for GAS, OKUM and MUH-1 are merged together with a methods file (\"OKUM.method\") into a universal data.frame file named 'GOM'. All of this happens in the \"Makefile.R\"\n```\n\n#### importing the data and assigning factors\n```{r makefile}\nsource(\"Makefile.R\")\n```\n#### defining the function for plotting methods vs. measurand mass fraction. Sample preparation methods are also marked in the plot.\n```{r plot_method function plotting measurand vs. method, include=FALSE, cache=TRUE}\n### function plot_method defined here. Automated plot of methods boxplots sorted by increasing method median. Enter with plot_method=('xx') #######\nplot_method <- function(x) {\n  element <- x\n  '%p%' <- function(x, y) {as.character(paste (x, y, sep =\"\"))}\n  prep <-  'Prep.'\n  method <- 'Method.'\n  anal.prep <- prep %p% measurand.name\n  anal.method <- method %p% measurand.name\n  anal <- GOM[[element]]\n  anal.prep <- GOM[[anal.prep]]\n  anal.method <- GOM[[anal.method]]\n  analyte <- data.frame(GOM$Lab, GOM$names, anal, anal.prep, anal.method )\n  analyte <- na.omit(analyte)\n  p <- ggplot(reorder_by(anal.method, ~anal, analyte, median), aes(anal.method, anal))+ geom_boxplot(outlier.shape = NA) + geom_jitter(aes(colour=anal.prep), size = 4.5, position = position_jitter(width = .2))\n  p + xlab(\"method\") + ylab(unit) + labs(title = measurand.name) + labs(colour = \"Prep\") + mytheme\n}\n```\n```{r plot_lab function plot measurand vs. lab, include=FALSE}\n###### function plot_lab #### \n# defined here. Automated plot of lab boxplots sorted by increasing lab mean and Horwitz function. Enter with plot_lab=('xx')\nplot_lab <- function(x, type, horw = FALSE, u = FALSE) {\n  element <- x\n  '%p%' <- function(x, y) {as.character(paste (x, y, sep =\"\"))}\n  prep <-  'Prep.'\n  method <- 'Method.'\n  anal.prep <- prep %p% measurand.name\n  anal.method <- method %p% measurand.name\n  anal <- GOM[[element]]\n  anal.prep <- GOM[[anal.prep]]\n  anal.method <- GOM[[anal.method]]\n  analyte <- data.frame(GOM$Lab, anal, anal.prep, anal.method )\n  analyte <- na.omit(analyte)\n  lab <- \"U\"\n  if(horw==\"TRUE\") {\n    reference.line <- median.before\n         switch(type, \n         M = hor <- 1*(0.01*reference.line)^0.8495, \n         T = hor <- 10000*1*(0.01*reference.line/10000)^0.8495)\n         u.lim <- reference.line + hor\n         u.2lim <- reference.line + 2*hor\n         l.lim <- reference.line - hor\n         l.2lim <- reference.line - 2*hor\n         } else  if (u == \"TRUE\") {\n           reference.line <- median.after\n             u.lim <- median.after + u2.a \n             u.2lim <- median.after + u2.a*t.value \n             l.lim <- median.after - u2.a \n             l.2lim <- median.after - u2.a*t.value \n           } else\n             {u.lim <- median.after\n             u.2lim <- median.after \n             l.lim <- median.after \n             l.2lim <- median.after               \n             }\n  p <- ggplot(reorder_by(GOM.Lab, ~anal, analyte, mean), aes(GOM.Lab, anal)) + geom_abline(intercept = reference.line, slope = 0) + geom_abline(intercept = u.2lim, slope = 0, linetype =\"dotted\") + geom_abline(intercept = l.2lim, slope = 0, linetype = \"dotted\") + geom_abline(intercept = u.lim, slope = 0, linetype =\"dashed\") + geom_abline(intercept = l.lim, slope = 0, linetype = \"dashed\")#  + geom_text( x = -Inf , y = u.2lim, label = lab) # works only for horwitz also annotations does not work\n  p <- p + geom_boxplot(aes(fill=anal.method)) + geom_point(size=4) + geom_point(aes(colour=anal.prep), size = 3.5)\n  p + xlab(\"lab\") + ylab(unit) + labs(title = measurand.name) + labs(colour = \"Prep\")  + geom_smooth(aes(group=1)) + mytheme \n}\n```\n#### defining the function of Youden plots\n\n```{r plot_youd function for youden plot, include=FALSE}\nplot_youd <- function(a, y, z) { # a = measurand, y and z ref\n  '%p%' <- function(a, b) {as.character(paste (a, b, sep =\"\"))}\n  switch(\n    y,\n    GAS = rm1 <- 2,\n    MUH = rm1 <- 1,\n    OKUM = rm1 <- 0\n  )\n  switch(\n    z,\n    GAS = rm2 <- 2,\n    MUH = rm2 <- 1,\n    OKUM = rm2 <- 0\n  )\n  if(rm1 > 0) \n  {RM1 <- a %p% '.' %p% rm1\n  } else \n  {\n    RM1 <- a\n  }\n  if(rm2 > 0) \n  {RM2 <- a %p% '.' %p% rm2\n  } else \n  {\n    RM2 <- a\n  }\n if(rm1 > 1)\n   {RM1.s <- GOM.sd[[RM1]]} else\n     {RM1.s <- GOM.sd[[RM1]]/sd(GOM.median[[RM1]], na.rm = TRUE)}# calculating the normalised standard deviations\n if(rm2 > 1)\n   {RM2.s <- GOM.sd[[RM2]]} else\n     {RM2.s <- GOM.sd[[RM2]]/sd(GOM.median[[RM2]], na.rm = TRUE)}# calculating the normalised standard deviations\n  RM1 <- GOM.median[[RM1]]\n  RM1 <- (RM1-median(RM1, na.rm = TRUE))/sd(RM1, na.rm = TRUE) #calculating z-scores\n  RM2 <- GOM.median[[RM2]]\n  RM2 <- (RM2-median(RM2, na.rm = TRUE))/sd(RM2, na.rm = TRUE) #calculating z-scores\n  RM <- data.frame(GOM.median$Lab, RM1, RM2, RM1.s, RM2.s) # creating a data frame for the measurand\n  # RM <- na.omit(RM) # removing all \"NA\"\n  p <- ggplot(RM, aes(RM1, RM2, label = GOM.median.Lab))  + xlim(-5, 5) + ylim(-5,5) + \n    geom_point(aes(colour=factor(GOM.median.Lab)), size = 4)\n  p <- p + xlab(y) + ylab(z) + labs(title = a) + labs(colour = \"GOM.median.Lab\") + mytheme + \n    geom_abline(intercept = 0, slope = 1) +  geom_abline(intercept = 2.8284, slope = 1) +  \n    geom_abline(intercept = - 2.8284, slope = 1) +  geom_abline(intercept = 2.8284, slope = - 1) +  \n    geom_abline(intercept = -2.8284, slope = - 1) + geom_text(data = NULL, x = -0.5, y = 2.85, label = \"z = 2\") + \n    geom_text(aes(colour=factor(GOM.median.Lab)), hjust=1, vjust=0) + theme(legend.position=\"none\") #+ stat_density2d(aes(fill = ..level..), geom=\"polygon\")\n  p  + geom_errorbar(aes(ymin=RM2-RM2.s, ymax=RM2+RM2.s)) + geom_errorbarh(aes(xmin=RM1-RM1.s, xmax=RM1+RM1.s))\n  \n}\n\n```\n#### initial calculations with complete data set\n\n```{r creating means}\n## means over packets within lab \nmeanGOM <- function(x) mean(x, na.rm=TRUE) # defining a function for further calcuations\nsdGOM <- function(x) sd(x, na.rm=TRUE) # defining a function for further calcuations, here for calculating standard deviations needed for Youden plot\nmeanGOM.packet <- ddply(GOM, c(\"Lab\", \"Packet\"), numcolwise(meanGOM)) # calculated the mean for each Packet within each Lab by calculating the mean of days and preparations lumped together\n## mean over mean of packets within lab\nGOM.mean <- ddply(meanGOM.packet, c(\"Lab\"), numcolwise(meanGOM))\nGOM.mean <- merge(GOM.mean, OKUM.methods, by=\"Lab\")\n```\n```{r creating median}\n## median over packets within lab \nmedianGOM <- function(x) median(x, na.rm=TRUE)\nmedianGOM.packet <- ddply(GOM, c(\"Lab\", \"Packet\"), numcolwise(medianGOM))\nGOM.sd <- ddply(medianGOM.packet, c(\"Lab\"), numcolwise(sdGOM))\n## median over median of packets within lab\nGOM.median <- ddply(medianGOM.packet, c(\"Lab\"), numcolwise(medianGOM))\nGOM.median <- merge(GOM.median, OKUM.methods, by=\"Lab\")\n```\n\n### plots before outlier removal and outlier removal\n\n```{r fig.width=7, fig.height=4, fig.keep='all'}\nsequence <- seq(from = 1, to = length(names(MUH.outlier)), by = 3)\ncol <- MUH.outlier[,c(sequence)]\ncol.names <- colnames(col)\nfor (m in col.names) {\n  measurand.name <- m\n  switch(\n    refmat,\n    GAS = rm1 <- 2,\n    MUH = rm1 <- 1,\n    OKUM = rm1 <- 0\n  )\n  if(rm1 > 0) \n  {measurand <- measurand.name %p% '.' %p% rm1\n  } else \n  {\n    measurand <- measurand.name\n  }\n  MorT <- grep(measurand.name, colnames(GOM), fixed=TRUE) # finding the position of the measurand.name in the Columnheaders of data frame GOM\n  ifelse(MorT[1]< 21, MorT <- 'M', MorT<-'T') # testing if measurand is a major or trace element/compound (col:5-20 majors)\n  ifelse(MorT == \"T\", unit <- 'mg/kg', unit <- 'g/100g') # testing which unit is needed  \n\nprint(plot_method(measurand))\n\n# outlier removal\n\noutlier <- MUH.outlier[[measurand.name]]\noutlier <- na.omit(outlier)\nleng <- length(outlier) ## counting the number of outliers for loop\nfor(i in seq(leng)) ##  looping\n  {\n  GOM[[measurand]] <- ifelse(GOM$Lab==outlier[i], NA, GOM[[measurand]]) ## replacing values of outlying lab with \"NA\" and defining new GOM\n  message(\"Lab \", outlier[i], \" was removed\")\n#  print(summary(GOM[[measurand]], na.rm=TRUE, digits=4))\n  }\n}\n```\n\n```{r calculating mean and median of candiate RM after outlier removal}\n\nmedianGOM.packet.after <- ddply(GOM, c(\"Lab\", \"Packet\"), numcolwise(medianGOM)) # median Lab and Packets after outlier removal\n## median over median of packets within lab\nGOM.median.after <- ddply(medianGOM.packet.after, c(\"Lab\"), numcolwise(medianGOM)) # creating a new table of median of labs after outlier removal for measurand but for entire table (all measurands)\nGOM.median.after <- merge(GOM.median.after, OKUM.methods, by=\"Lab\")\nGOM.median.after.df <- data.frame(apply(GOM.median.after[2:56], 2, median, na.rm=TRUE)) # creating a new table with final property values based on median\nnames(GOM.median.after.df) <- c(\"mass fraction\")\nmeanGOM.packet <- ddply(GOM, c(\"Lab\", \"Packet\"), numcolwise(meanGOM))\nmeanGOM.packet.after <- ddply(GOM, c(\"Lab\", \"Packet\"), numcolwise(meanGOM)) # mean Lab and Packets after outlier removal\n## mean over mean of packets within lab\nGOM.mean.after <- ddply(meanGOM.packet.after, c(\"Lab\"), numcolwise(meanGOM)) # creating a new table of mean of labs after outlier removal for measurand but for entire table (all measurands)\nGOM.mean.after <- merge(GOM.mean.after, OKUM.methods, by=\"Lab\")\nGOM.mean.after.df <- data.frame(apply(GOM.mean.after[2:56], 2, mean, na.rm=TRUE)) # creating a new table with final property values based on mean\nnames(GOM.mean.after.df) <- c(\"mass fraction\")\n```\n### Nested random effects in data analysis: two way ANOVA  \n\nThis model can be used when the results of the interlaboratory study are used to confirm the homogeneity of the material as well as to characterise it. The experimental scheme is illustrated in Fig X for the particular case of the IAG protocol. When the ILC consists of different methos, the result can be expressed by the equation  \n\n$x_{ijk} = \\mu + A_{i} + B{ij} + \\epsilon_{ijk}$  \n\nwhere  \n\n$x_{ijk}$ is the $k$th result of sample unit j reported from method/laboratory $i$,  \n$A_{i}$ is the error due to method/laboratory $i$,  \n$B{ij}$ is the error due to the $j$th sample unit within method/laboratory $i$,\n$\\epsilon_{ijk}$ is the measurement error.  \n\nThe parameters to be estimated are the grand mean, the between-laboratory standard deviation $s_{L}$, the between-bottle standard deviation $s_{bb}$ and the repeatability standard deviation $s_{r}$. The are related as follows  \n\n$s_{L} = \\sqrt{Var(A_{i})}$  \n$s_{bb} = \\sqrt{Var(B_{ij})}$  \n$s_{r} = \\sqrt{Var(\\epsilon_{ijk})}$  \n\nThe formulae for computing the above-mentioned estimates read as follows. The grand mean is computed using\n\n$\\bar x =  \\frac{1}{\\sum_{i=1}^{p}\\sum_{j=1}^{b_i}n_{ij}} \\sum_{i=1}^{p} \\sum_{j=1}^{b_i} \\sum_{k=1}^{n_ij}x_{ijk}$  \n\nwhere $p$ denotes the number of laboratories, $b_{i}$ the number of bottles used by method/laboratory $i$, and $n_{ij}$ is the number of replicates measured on bottle $_{ij}$. The variances are computed as follows  \n\n$Var(\\epsilon_{ijk}) = MS_{within} = s^2_r$  \n$Var(B_{ij}) = \\frac{MS_{B \\subset A} - MS_{within}}{n_0} = s^2_bb$   \n$Var(A_{i}) = \\frac{MS_{among} - n'_0Var(B_{ij})-Var(\\epsilon_{ijk})}{(nb)_0} = s^2_L$  \n\n\nwhere  \n\n$MS_{among} = \\frac{\\sum_{i=1}^{p} n_i (\\bar x_A - \\bar x)^2}{p-1}$  \n\n$MS_{B \\subset A} = \\frac{\\sum_{i=1}^{p}\\sum_{j=1}^{b_i}n_{ij}(\\bar x_B - \\bar x_A)^2}{\\sum_{i=1}^{p}b_i - p}$  \n\n$MS_{within} = \\frac{\\sum_{i=1}^{p} \\sum_{j=1}^{b_i} \\sum_{k=1}^{n_ij}(x_{ijk}-\\bar x_B)^2}{\\sum_{i=1}^{p}\\sum_{j=1}^{b_i}n_{ij}-\\sum_{i=1}^{p}b_{i}}$  \n\nand \n\n$n'_0 = \\frac{\\sum_{i=1}^p\\left(\\frac{\\sum_{j=1}^{b_i}n^2_{ij}}{\\sum_{j=1}^{b_i}n_{ij}}\\right)-\\frac{\\sum_{i=1}^{p}\\sum_{j=1}^{b_i}n^2_{ij}}{\\sum_{i=1}^{p}\\sum_{j=1}^{b_i}n_{ij}}}{p-1}$  \n\n$n_0 = \\frac{\\sum_{i=1}^{p}\\sum_{j=1}^{b_i}n_{ij} -\\sum_{i=1}^p\\left(\\frac{\\sum_{j=1}^{b_i}n^2_{ij}}{\\sum_{j=1}^{b_i}n_{ij}}\\right)}{\\sum_{i=1}^{p}b_i-p}$  \n\n$(nb)_0 = \\frac{\\sum_{i=1}^{p}\\sum_{j=1}^{b_i}n_{ij} -\\frac{\\sum_{i=1}^p({\\sum_{j=1}^{b_i}n_{ij}})^2}{\\sum_{i=1}^{p}\\sum_{j=1}^{b_i}n_{ij}}}{p-1}$  \n\n\n###  solutions of the above equations in $R$  \n\nANOVA is calculated based on a linear model using the using \"linear mixed effects models\" of package nlme (lme {nlme})  \n\nGOM.lme <- lme(measurand ~ 1, random = ~ 1|Lab/Packet, data=DF.lme) # linear model with random effects  \n\nthe variance components are extrated with package ape (varcomp {ape})  \n\n$s^2_L$ = sL2 <- varcomp(GOM.lme, FALSE, FALSE)[[1]] # between-laboratory variance  \n$s^2_{bb}$ = sbb2 <- varcomp(GOM.lme, FALSE, FALSE)[[2]] # between bottle variance  \n$s^2_r$ = sr2 <- varcomp(GOM.lme, FALSE, FALSE)[[3]] # repeatability standard deviation  \n\nThe characterisation uncertainty $u_{char}$ is calculated  \n\nu1 <- sqrt(sL2/p+sbb2/p/r+sr2/p/r/4) \n\nwhich is equivalent to  \n\n$u_1 = \\sqrt{\\frac{s^2_L}{p}-\\frac{s^2_r}{np}-\\frac{s^2_{bb}}{npr}}$\n\nThis approach is not completly correct as it assumes 4 replicates per bottle  \n\nu2 <- attr(GOM.lme$fixDF,\"varFixFact\") # this approach takes unbalanced data into account and is used for all further calculations.  \n\nThe between day variance is neglected here but the uncertainty component due to inhomogeneity is taken into account through the\n$s^2_{bb}$ component.\n\n\n\n```{r fig.width=6, fig.height=4, fig.keep='all'}\nfor (m in col.names) {\n  measurand.name <- m\n  switch(\n    refmat,\n    GAS = rm1 <- 2,\n    MUH = rm1 <- 1,\n    OKUM = rm1 <- 0\n  ) \n  if(rm1 > 0) \n  {measurand <- measurand.name %p% '.' %p% rm1\n  } else \n  {\n    measurand <- measurand.name\n  }\n  MorT <- grep(measurand.name, colnames(GOM), fixed=TRUE) # finding the position of the measurand.name in the Columnheaders of data frame GOM\n  ifelse(MorT[1]< 21, MorT <- 'M', MorT<-'T') # testing if measurand is a major or trace element/compound (col:5-20 majors)\n  ifelse(MorT == \"T\", unit <- 'mg/kg', unit <- 'g/100g') # testing which unit is needed \n  ## calculating method parameters\n#  '%p%' <- function(x, y) {as.character(paste (x, y, sep =\"\"))}\nmean <- mean(tapply(GOM[[measurand]], GOM$Lab, mean, na.rm=TRUE), na.rm=TRUE)\nmean.before <- mean(GOM.mean[[measurand]], na.rm=TRUE)\nmedian.before <- median(GOM.median[[measurand]], na.rm=TRUE)\nmedian.after <- median(GOM.median.after[[measurand]], na.rm=TRUE) # median of the individual measurand after outlier removal\nprep <-  'Prep.'\nmethod <- 'Method.'\nanal.prep <- prep %p% measurand.name\nanal.method <- method %p% measurand.name\nanal <- GOM.median.after[[measurand]]\nanal.prep <- GOM.median.after[[anal.prep]]\nanal.method <- GOM.median.after[[anal.method]]\nanalyte <- data.frame(GOM.median.after$Lab, GOM.median.after$names, anal, anal.prep, anal.method )\nanalyte <- na.omit(analyte)\n\n  bymethod.n <- ddply(analyte, c(\"anal.method\"), summarise, \n                      N=length(anal), \n                      mean = round(mean(anal), 3), \n                      median = round(median(anal), 3), \n                      sd = round(sd(anal),3), \n                      se = round(sd/sqrt(N),3))\n\nmeanGOM.packet.after$Lab <- as.factor(meanGOM.packet$Lab) # using only the median of the 3 packages per lab\nmeanGOM.packet.after$Packet <- as.factor(meanGOM.packet$Packet)\nanal <- meanGOM.packet.after[[measurand]]\nDF.lme <- data.frame(meanGOM.packet.after$Lab, meanGOM.packet.after$Packet, meanGOM.packet.after[[measurand]])\nDF.lme <- na.omit(DF.lme)\nnames(DF.lme) <- c(\"Lab\", \"Packet\", \"measurand\")\nGOM.lme <- lme(measurand ~ 1, random = ~ 1|Lab/Packet, data=DF.lme) # linear model with random effects\nsL2.a <- varcomp(GOM.lme, FALSE, FALSE)[[1]] # between-laboratory variance\nsbb2.a <- varcomp(GOM.lme, FALSE, FALSE)[[2]] # between bottle standard deviation\nsr2.a <- varcomp(GOM.lme, FALSE, FALSE)[[3]] # repeatability standard deviation\nn.p <- dim(DF.lme)[1] # number of obervations\np <- length(unique(DF.lme$Lab)) # haven't found a better way how to extract the number of labs (number of groups)\nr <- length(unique(DF.lme$Packet))\nt.value <- qt(0.975,df=p-1)\nu1.a <- sqrt(sL2.a/p+sbb2.a/p/r+sr2.a/p/r/4) # calculating the standard uncertainty of characterization\nu2.a <- attr(GOM.lme$fixDF,\"varFixFact\") # gives the same results as u1, amazing!\n# plot(DF.lme)\nanalyte.noPP <- subset(analyte, analyte$anal.prep!=\"PP\") # Removing all PP preparations for comparison reasons\nmedian.after.noPP <- median(analyte.noPP$anal)\noutlier <- ifelse(outlier==\"0\", \"X\", outlier)\nprint(measurand)\nqqnorm(GOM.median.after[[measurand]])\nqqline(GOM.median.after[[measurand]])\nreference.line <- median.after\nu.Ulim <- median.after + u2.a*t.value\nl.Ulim <- median.after - u2.a*t.value\nbymethod <- ggplot(bymethod.n, aes(x=anal.method, y=median))+geom_point(size=4)+geom_errorbar(aes(ymin=median-se, ymax=median+se), width=0.05)+ geom_abline(intercept = reference.line, slope = 0) + geom_abline(intercept = u.Ulim, slope = 0, linetype =\"dotted\") + geom_abline(intercept = l.Ulim, slope = 0, linetype = \"dotted\") + mytheme\nplot.lab <- plot_lab(measurand, MorT, horw = FALSE, u = TRUE)\n# grid.arrange(bymethod, plot.lab, ncol=2)\nprint(plot.lab)\n# print(bymethod.n)\noutlier.type.name <- measurand.name %p% \".outlier.type\" # defining if outlier is selected (\"Y\" or NA)\noutlier.dist.type <- measurand.name %p% \".dist.type\" # defining if outlier is based on Y = Youden plot, M = Madel's k, P = pressed powder pellet, D = detection limit \nout.measurand <- data.frame(MUH.outlier[[measurand.name]], MUH.outlier[[outlier.type.name]], MUH.outlier[[outlier.dist.type]])\n# out.measurand <- cbind(MUH.outlier[[measurand.name]], MUH.outlier[[outlier.type.name]])\nnames(out.measurand) <- c(\"outlier.lab\",\"outlier.type\", \"outlier.dist\" )\nproperty.value.dist.type <- out.measurand[1,3]\nproperty.value <- ifelse(property.value.dist.type == \"median\", median.after, mean)\ndf <- data.frame(Sys.Date(), refmat, measurand.name, signif(mean.before, 4), signif(mean,4), signif(median.before,4), signif(median.after,4), signif(median.after.noPP,4), unit, signif(sL2.a,3), signif(sbb2.a,3), signif(sr2.a,4), signif(u1.a,3), signif(u2.a,3), round(t.value,2), signif(outlier,2), signif(p,2), property.value.dist.type, signif(property.value,4), signif(u2.a*t.value,3))\nwrite.table(df, \"df1.txt\", row.names=FALSE, append=TRUE, col.names=FALSE)\n  }\n```\n\n```{r}\ndf1 <- read.table(\"~/GitHub/GOMcertification/df1.txt\", header=T, quote=\"\\\"\")\nfinal <- ddply(df1, c(\"date\",\"RM\",\"measurand\",\"based.on\", \"unit\"), numcolwise(meanGOM))\nwrite.csv(final,\"MUHall.csv\")\n```\n#### final\n\n```{r all data table, results='asis'} \n# kable(final, format = \"markdown\", padding=0, digits=c(0,0,0,0,3,3,3,3,3,3,3,3,4,4,4,0,0,3,3,0))\n#library(xtable)\n#xt <- xtable(final, digits=c(0,0,0,0,0,3,3,3,3,3,3,3,3,3,3,2,0,0,3,3,0))\n#print(xt, type=\"html\")\n#library(Gmisc)\n# htmlTable(final)\n```\n\n```{r certified values with U, results='asis'}\ncertified.values <- data.frame(final$date, final$RM, final$measurand, final$t.value, final$labs.remaining, final$property.value, final$U, final$unit)\nnames(certified.values) <- c(\"date\", \"RM\", \"measurand\", \"t.value\", \"n\", \"PV\", \"U\", \"unit\")\nwrite.table(certified.values, \"CV1.txt\", row.names=FALSE)\nCV2 <- subset.data.frame(certified.values, n >= 10) # CV based on IAG protocol with n >= 10\nCV3 <- subset.data.frame(certified.values, n < 10) # Information value based on IAG protocol with n < 10\nwrite.table(CV2, \"CV2.txt\", row.names=FALSE) # just CV\nwrite.table(CV3, \"CV2.txt\", row.names=FALSE, append=TRUE, col.names=FALSE) #CV and IV\nCV <- read.table(\"~/GitHub/GOMcertification/CV2.txt\", header=TRUE, quote=\"\\\"\")\n#xtCV <- xtable(CV, digits=c(0,0,0,0,2,0,4,4,0))\n#print(xtCV, type=\"html\")\nkable(CV, digits=c(0,0,0,2,2,4,4,0), padding=1)\n```\n```{r}\nREE.chondrites <- read.csv(\"~/GitHub/REE/REE.chondrites.csv\", sep=\";\") # reading chondrite normalisig values from file\nREE.chondrites <- rename(REE.chondrites, c(\"norm\"= \"REE\")) # renaming the column to make it suitable for merging\nREE <- c(\"La\",\"Ce\",\"Pr\", \"Nd\", \"Pm\", \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\") # needed for extracting the REE from the final table sheet\nRM <- read.table(\"~/GitHub/GOMcertification/CV2.txt\", header=TRUE, quote=\"\\\"\") # reading all the finalised property values\nRM.REE <- subset(RM, measurand %in% REE, select=c(RM,measurand,PV)) # extacting onl the REE values\nRM.REE <- rename(RM.REE, c(\"measurand\"=\"REE\")) # renaming the column head suitable for merging\nRM.REE <- merge(REE.chondrites, RM.REE, by = \"REE\", all.x=TRUE) # merging the data set so that element Pm is also included\nRM.normalised <- ddply(RM.REE, c(\"RM\"), transform, normalised = PV/chondrite) # adding a chondrite normalised column\nRM.normalised[15,5] <- (RM.normalised[9,5]+RM.normalised[11,5])/2\nREEtheme <- theme_grey() + theme(plot.title = element_text(colour = \"black\", size = rel(2)))+ theme(axis.title.x = element_text(size = rel(1.8)))+ theme(axis.title.y = element_text(size = rel(1.8)))+theme(axis.text.x = element_text(size = rel(1.2))) + theme(axis.text.y = element_text(size = rel(1.2)))\np <- ggplot(data=RM.normalised, aes(x=REE, y=normalised, group=1)) + geom_line(size= 1.2)\np + scale_x_discrete(limits=c(\"La\",\"Ce\",\"Pr\", \"Nd\", \"Pm\", \"Sm\", \"Eu\", \"Gd\", \"Tb\", \"Dy\", \"Ho\", \"Er\", \"Tm\", \"Yb\", \"Lu\"))  + coord_trans(y=\"log2\") + REEtheme\n```\n\n```{r sessionInfo, include=TRUE, echo=TRUE, results='markup'}\nsessionInfo()\n```\n ",
    "created" : 1406232141254.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3936585817",
    "id" : "E374B18D",
    "lastKnownWriteTime" : 1407098780,
    "path" : "~/GitHub/GOMcertification/MUH2.Rmd",
    "project_path" : "MUH2.Rmd",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}